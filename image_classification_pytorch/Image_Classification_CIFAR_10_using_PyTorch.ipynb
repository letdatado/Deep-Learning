{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification CIFAR-10 using PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vumx9lj2b9Ci",
        "LayQbkRSTeWb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2ea4236f3884d4889c7994dc31dc038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_120fb2ea35324b1a9d9b815674125d16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a48d0c6efdb34f859aab72b2960c39a4",
              "IPY_MODEL_8d9b4aabab6b496981aba806dfdfb4d4",
              "IPY_MODEL_01be488369c44dbd85285cf676694398"
            ]
          }
        },
        "120fb2ea35324b1a9d9b815674125d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a48d0c6efdb34f859aab72b2960c39a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6badd7557fa4f24a50e986920ada000",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfc4a3e743ed4a0f84af6e01e4343a80"
          }
        },
        "8d9b4aabab6b496981aba806dfdfb4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27b75d00d6bf42ba983accae99957674",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54a804c0d05d42bcb784c2f1641c47d0"
          }
        },
        "01be488369c44dbd85285cf676694398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_332adba3c170493f9ce7fe6766ac2b98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:11&lt;00:00, 15656108.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_affa5aef97fc469fb574972845387233"
          }
        },
        "e6badd7557fa4f24a50e986920ada000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfc4a3e743ed4a0f84af6e01e4343a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27b75d00d6bf42ba983accae99957674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54a804c0d05d42bcb784c2f1641c47d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "332adba3c170493f9ce7fe6766ac2b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "affa5aef97fc469fb574972845387233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Importing Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "3RiRiqVeTXWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "metadata": {
        "id": "ynsaGrmEFGKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and Preprocessing the Dataset (with the batch_size of 16)"
      ],
      "metadata": {
        "id": "tLvRzrEOTzhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the dataset so that each channel has zero mean and unitary standard deviation.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 16\n",
        "# loading datasets with dataloaders\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "# Classes (10)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "c2ea4236f3884d4889c7994dc31dc038",
            "120fb2ea35324b1a9d9b815674125d16",
            "a48d0c6efdb34f859aab72b2960c39a4",
            "8d9b4aabab6b496981aba806dfdfb4d4",
            "01be488369c44dbd85285cf676694398",
            "e6badd7557fa4f24a50e986920ada000",
            "cfc4a3e743ed4a0f84af6e01e4343a80",
            "27b75d00d6bf42ba983accae99957674",
            "54a804c0d05d42bcb784c2f1641c47d0",
            "332adba3c170493f9ce7fe6766ac2b98",
            "affa5aef97fc469fb574972845387233"
          ]
        },
        "id": "iy3qXxOGTOz5",
        "outputId": "d47fcb51-d278-4e0c-cbbf-bcd931394912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2ea4236f3884d4889c7994dc31dc038",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for training and testing the models"
      ],
      "metadata": {
        "id": "vumx9lj2b9Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Develope a train and test mechanism \n",
        "def train_and_test(model, optimizer, loss_fn, train_loader, test_loader, epochs=20, device=\"cpu\"):\n",
        "    for epoch in range(1, epochs+1):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            # Reset the gradient\n",
        "            optimizer.zero_grad()\n",
        "            # Allocate inputs and targets to batch for training\n",
        "            inputs, targets = batch\n",
        "            # Selecting the processor\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs)\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(output, targets)\n",
        "            # Back pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Calculation of loss\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        \n",
        "        # Evaluating the model on test\n",
        "        model.eval()\n",
        "        num_correct = 0 \n",
        "        num_examples = 0\n",
        "        # loop within the batch\n",
        "        for batch in test_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output,targets) \n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "            # Evaluating the performance of the model\n",
        "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
        "            num_correct += torch.sum(correct).item()\n",
        "            num_examples += correct.shape[0]\n",
        "        valid_loss /= len(test_loader.dataset)\n",
        "        # Accuracy\n",
        "        accuracy = num_correct/num_examples\n",
        "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
        "        valid_loss, accuracy))\n",
        "\n"
      ],
      "metadata": {
        "id": "5S0UsfpTcDFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Simple Neural Network\n",
        "\n",
        "This is a Simple Feed Forward neural network made without the proposed improvements"
      ],
      "metadata": {
        "id": "LayQbkRSTeWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # Input layer, taking in the input values, in our case, are 32*32*3 and an arbitrary output to the first hidden layer\n",
        "        self.fc1 = nn.Linear(32*32*3, 84) \n",
        "        self.fc2 = nn.Linear(84, 50) # \n",
        "        self.fc3 = nn.Linear(50,10) # 84 to 10\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Convert to 1D vector\n",
        "        x = x.view(-1, 32*32*3)\n",
        "        # layers of ReLu\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiation\n",
        "simplenet = SimpleNet()\n",
        "\n",
        "# Choosing Optimizer with learning rate\n",
        "optimizer = optim.Adam(simplenet.parameters(), lr=0.001)\n",
        "\n",
        "# Preferring\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") \n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "simplenet.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_PlJQAYTkKa",
        "outputId": "9e12cfea-d483-48cc-abff-fb0a5dff474e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNet(\n",
              "  (fc1): Linear(in_features=3072, out_features=84, bias=True)\n",
              "  (fc2): Linear(in_features=84, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train and test\n",
        "train_and_test(simplenet, optimizer,torch.nn.CrossEntropyLoss(), trainloader, testloader, epochs=10, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR1H6Vq-UsV_",
        "outputId": "7616b4e2-54d2-4341-ae6d-173314a19d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 1.66, Validation Loss: 1.52, accuracy = 0.46\n",
            "Epoch: 2, Training Loss: 1.48, Validation Loss: 1.48, accuracy = 0.48\n",
            "Epoch: 3, Training Loss: 1.40, Validation Loss: 1.44, accuracy = 0.49\n",
            "Epoch: 4, Training Loss: 1.34, Validation Loss: 1.43, accuracy = 0.50\n",
            "Epoch: 5, Training Loss: 1.30, Validation Loss: 1.44, accuracy = 0.50\n",
            "Epoch: 6, Training Loss: 1.26, Validation Loss: 1.41, accuracy = 0.51\n",
            "Epoch: 7, Training Loss: 1.23, Validation Loss: 1.44, accuracy = 0.50\n",
            "Epoch: 8, Training Loss: 1.20, Validation Loss: 1.45, accuracy = 0.51\n",
            "Epoch: 9, Training Loss: 1.17, Validation Loss: 1.45, accuracy = 0.51\n",
            "Epoch: 10, Training Loss: 1.14, Validation Loss: 1.43, accuracy = 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network with enhancements like Convolutional Layers, DropOut, and MaxPooling"
      ],
      "metadata": {
        "id": "N8Xp6vK4NyIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # input / output channels and kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "cnnnet = CNNNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnnnet.parameters(), lr=0.001)\n",
        "cnnnet.to(device)\n",
        "train_and_test(cnnnet, optimizer, criterion, trainloader, testloader, epochs=10, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OukQVBQn9RnI",
        "outputId": "ddb28e00-2eab-4793-bbaa-b7869023717f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 1.55, Validation Loss: 1.35, accuracy = 0.51\n",
            "Epoch: 2, Training Loss: 1.28, Validation Loss: 1.22, accuracy = 0.56\n",
            "Epoch: 3, Training Loss: 1.16, Validation Loss: 1.15, accuracy = 0.60\n",
            "Epoch: 4, Training Loss: 1.08, Validation Loss: 1.16, accuracy = 0.59\n",
            "Epoch: 5, Training Loss: 1.02, Validation Loss: 1.15, accuracy = 0.61\n",
            "Epoch: 6, Training Loss: 0.97, Validation Loss: 1.11, accuracy = 0.62\n",
            "Epoch: 7, Training Loss: 0.92, Validation Loss: 1.09, accuracy = 0.63\n",
            "Epoch: 8, Training Loss: 0.88, Validation Loss: 1.05, accuracy = 0.64\n",
            "Epoch: 9, Training Loss: 0.85, Validation Loss: 1.08, accuracy = 0.64\n",
            "Epoch: 10, Training Loss: 0.82, Validation Loss: 1.10, accuracy = 0.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNet1(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNNNet1, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(32, 128, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "     \n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "44zhNv07Aa9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intantiation\n",
        "cnnnet1 = CNNNet1()\n"
      ],
      "metadata": {
        "id": "ENS_vsS_AbF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnnet1.to(device)\n",
        "\n",
        "# Optimizer with learning rate\n",
        "optimizer = optim.Adam(cnnnet1.parameters(), lr=0.001) \n",
        "\n",
        "# Loss Criterion\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "kw0x_ygXAbNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test(cnnnet1, optimizer, criterion, trainloader, testloader, epochs=10, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFpm2upnAbVk",
        "outputId": "8398a01d-1168-442d-8176-f906f635579c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 1.63, Validation Loss: 1.39, accuracy = 0.50\n",
            "Epoch: 2, Training Loss: 1.36, Validation Loss: 1.28, accuracy = 0.54\n",
            "Epoch: 3, Training Loss: 1.24, Validation Loss: 1.28, accuracy = 0.55\n",
            "Epoch: 4, Training Loss: 1.17, Validation Loss: 1.19, accuracy = 0.58\n",
            "Epoch: 5, Training Loss: 1.11, Validation Loss: 1.16, accuracy = 0.59\n",
            "Epoch: 6, Training Loss: 1.06, Validation Loss: 1.20, accuracy = 0.58\n",
            "Epoch: 7, Training Loss: 1.02, Validation Loss: 1.12, accuracy = 0.61\n",
            "Epoch: 8, Training Loss: 0.98, Validation Loss: 1.13, accuracy = 0.61\n",
            "Epoch: 9, Training Loss: 0.95, Validation Loss: 1.13, accuracy = 0.61\n",
            "Epoch: 10, Training Loss: 0.91, Validation Loss: 1.14, accuracy = 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets increase the complexity of the model by resizing the input, adding some extra hidden layers as well as Adaptive Pooling"
      ],
      "metadata": {
        "id": "iU1F1YUQH7vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)), # resize the images from 32*32 to 64*64\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ATn8aZ4j0X",
        "outputId": "9e66d054-a723-4943-931d-e2d3877fdd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNNet2(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNNNet2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(384, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((3, 3))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.10),\n",
        "            nn.Linear(256 * 3 * 3, 1028),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(1028, 1028),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1028, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Xir-FhT3U_PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intantiation\n",
        "cnnnet2 = CNNNet2()\n"
      ],
      "metadata": {
        "id": "CozjxeNDVHNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnnet2.to(device)\n",
        "\n",
        "# Optimizer with learning rate\n",
        "optimizer = optim.Adam(cnnnet2.parameters(), lr=0.001) "
      ],
      "metadata": {
        "id": "I6LKNkudVXLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test(cnnnet2, optimizer,torch.nn.CrossEntropyLoss(), trainloader, testloader, epochs=10, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPcEfzwRVhXz",
        "outputId": "cc1af2a3-29fe-4ed6-c7ed-f981dd3ccc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Training Loss: 1.91, Validation Loss: 1.70, accuracy = 0.34\n",
            "Epoch: 2, Training Loss: 1.63, Validation Loss: 1.56, accuracy = 0.42\n",
            "Epoch: 3, Training Loss: 1.51, Validation Loss: 1.47, accuracy = 0.47\n",
            "Epoch: 4, Training Loss: 1.43, Validation Loss: 1.39, accuracy = 0.49\n",
            "Epoch: 5, Training Loss: 1.38, Validation Loss: 1.41, accuracy = 0.51\n",
            "Epoch: 6, Training Loss: 1.34, Validation Loss: 1.35, accuracy = 0.52\n",
            "Epoch: 7, Training Loss: 1.31, Validation Loss: 1.31, accuracy = 0.53\n",
            "Epoch: 8, Training Loss: 1.28, Validation Loss: 1.30, accuracy = 0.54\n",
            "Epoch: 9, Training Loss: 1.26, Validation Loss: 1.25, accuracy = 0.56\n",
            "Epoch: 10, Training Loss: 1.24, Validation Loss: 1.36, accuracy = 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "- A simple neural net could attain a mediocre Accuracy\n",
        "- Increasing batchsize resulted in better accuracy. So does an increase in Drop out.\n",
        "- Increasing the learning rate does increase the accuracy to some extent, but I doubt that the model is rather getting stuck in the incorrect minima\n",
        "\n",
        "## Proposals:\n",
        "- The scheduled decrease of learning rate of the epochs (for example, after each 10th)\n",
        "- Using the Optmizer (SGD) with momentum less than 1\n",
        "- Increament in the batchsize\n",
        "- Batch Normalization\n",
        "- Data Augmentation (gradual) to the training set\n"
      ],
      "metadata": {
        "id": "f3G2F0IFvXFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IIQsgIfgrFhe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}